{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments imports\n",
    "from ternary_weight_mlp import *\n",
    "import json\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution found\n",
      "Optimal solution found\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "INIITIAL_LEARNING_RATE  = 0.001  # Starting learning rate\n",
    "MAXIMUM_LEARNING_RATE = 0.5   # Maximum learning rate\n",
    "EPOCHS = 50000\n",
    "ALPHA = 0.5\n",
    "LAMBDA_MAGNITUDE = 0.1\n",
    "LAMBDA_POLARITY = 0.1\n",
    "LAMBDA_INTEGERS = 0.001\n",
    "LAMBDA_SPARSITY = 0.01\n",
    "X_train, y_train, X_test, y_test = create_torch_XOR_dataset()\n",
    "\n",
    "EVALUTION_RUNS = 10\n",
    "THRESHOLD = 0.02\n",
    "\n",
    "# Counter for 100% accuracy runs\n",
    "perfect_accuracy_count = 0\n",
    "evaluation_results = []\n",
    "\n",
    "for _ in range(EVALUTION_RUNS):\n",
    "    model_XOR = TwoLayerMLP().double()\n",
    "\n",
    "    # define the loss\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_XOR.parameters(), lr=INIITIAL_LEARNING_RATE, eps=1e-7)\n",
    "\n",
    "    all_loss = train_with_rectified_L2(model_XOR, \n",
    "                                    loss_function, \n",
    "                                    optimizer, \n",
    "                                    X_train, \n",
    "                                    y_train,\n",
    "                                    no_of_epochs=EPOCHS,\n",
    "                                    ALPHA=ALPHA,\n",
    "                                    LAMBDA_MAGNITUDE=LAMBDA_MAGNITUDE,\n",
    "                                    LAMBDA_POLARITY=LAMBDA_POLARITY,\n",
    "                                    LAMBDA_INTEGERS=LAMBDA_INTEGERS,\n",
    "                                    initial_lr=INIITIAL_LEARNING_RATE,\n",
    "                                    max_lr=MAXIMUM_LEARNING_RATE)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    inputs = [torch.tensor([[0.0, 0.0]], dtype=torch.float64), torch.tensor([[0.0, 1.0]], dtype=torch.float64), torch.tensor([[1.0, 0.0]], dtype=torch.float64), torch.tensor([[1.0, 1.0]], dtype=torch.float64)]\n",
    "    expected_outputs = [0.0, 1.0, 1.0, 0.0]\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for input_tensor, expected_output in zip(inputs, expected_outputs):\n",
    "        model_output = model_XOR(input_tensor).item()\n",
    "        if abs(model_output - expected_output) <= THRESHOLD:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(expected_outputs)\n",
    "\n",
    "    if accuracy == 1.0:\n",
    "        perfect_accuracy_count += 1\n",
    "\n",
    "    # Evaluate interpretability\n",
    "    results = evaluate_logic_gates_in_network(model_XOR, 2)\n",
    "    results['accuracy'] = accuracy\n",
    "\n",
    "    evaluation_results.append(results)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('evaluation_results.json', 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer MLP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution found\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "INIITIAL_LEARNING_RATE  = 0.001  # Starting learning rate\n",
    "MAXIMUM_LEARNING_RATE = 0.5   # Maximum learning rate\n",
    "EPOCHS = 50000\n",
    "ALPHA = 0.5\n",
    "LAMBDA_MAGNITUDE = 0.1\n",
    "LAMBDA_POLARITY = 0.1\n",
    "LAMBDA_INTEGERS = 0.001\n",
    "LAMBDA_SPARSITY = 0.01\n",
    "X_train, y_train, X_test, y_test = create_torch_A_XOR_B_AND_C_NAND_C_dataset()\n",
    "\n",
    "EVALUTION_RUNS = 10\n",
    "THRESHOLD = 0.02\n",
    "\n",
    "# Counter for 100% accuracy runs\n",
    "perfect_accuracy_count = 0\n",
    "evaluation_results = []\n",
    "\n",
    "for _ in range(EVALUTION_RUNS):\n",
    "    model_3_layer_MLP = SparseThreeLayerMLP2().double()\n",
    "\n",
    "    # define the loss\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_3_layer_MLP.parameters(), lr=INIITIAL_LEARNING_RATE, eps=1e-7)\n",
    "\n",
    "    all_loss = train_with_rectified_L2(model_3_layer_MLP, \n",
    "                                    loss_function, \n",
    "                                    optimizer, \n",
    "                                    X_train, \n",
    "                                    y_train,\n",
    "                                    no_of_epochs=EPOCHS,\n",
    "                                    ALPHA=ALPHA,\n",
    "                                    LAMBDA_MAGNITUDE=LAMBDA_MAGNITUDE,\n",
    "                                    LAMBDA_POLARITY=LAMBDA_POLARITY,\n",
    "                                    LAMBDA_INTEGERS=LAMBDA_INTEGERS,\n",
    "                                    initial_lr=INIITIAL_LEARNING_RATE,\n",
    "                                    max_lr=MAXIMUM_LEARNING_RATE)\n",
    "\n",
    "    # Evaluate accuracy for the function (A xor B) and not C\n",
    "    inputs = [\n",
    "        torch.tensor([[0.0, 0.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 0.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 1.0, 0.0]], dtype=torch.float64)\n",
    "    ]\n",
    "    expected_outputs = [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for input_tensor, expected_output in zip(inputs, expected_outputs):\n",
    "        model_output = model_3_layer_MLP(input_tensor).item()\n",
    "        if abs(model_output - expected_output) <= THRESHOLD:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(expected_outputs)\n",
    "\n",
    "    if accuracy > 0.9:\n",
    "        perfect_accuracy_count += 1\n",
    "\n",
    "    # Evaluate interpretability\n",
    "    results = evaluate_logic_gates_in_network(model_3_layer_MLP, 2)\n",
    "    results['accuracy'] = accuracy\n",
    "\n",
    "    evaluation_results.append(results)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('evaluation_results.json', 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.675\n",
      "Average Percentage: 84.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "def load_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Calculate the average accuracy and percentage\n",
    "def calculate_averages(data):\n",
    "    total_accuracy = 0\n",
    "    total_percentage = 0\n",
    "    count = len(data)\n",
    "    \n",
    "    for record in data:\n",
    "        total_accuracy += record[\"accuracy\"]\n",
    "        total_percentage += record[\"percentage\"]\n",
    "    \n",
    "    average_accuracy = total_accuracy / count if count != 0 else 0\n",
    "    average_percentage = total_percentage / count if count != 0 else 0\n",
    "    \n",
    "    return average_accuracy, average_percentage\n",
    "\n",
    "\n",
    "filename = 'experiment_results/evaluation_results_3layer_MLP.json'  # Replace with your actual JSON file name\n",
    "data = load_json(filename)\n",
    "average_accuracy, average_percentage = calculate_averages(data)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Average Percentage: {average_percentage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Neuron MLP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "INIITIAL_LEARNING_RATE  = 0.005  # Starting learning rate\n",
    "MAXIMUM_LEARNING_RATE = 0.5   # Maximum learning rate\n",
    "EPOCHS = 100000\n",
    "ALPHA = 0.5\n",
    "LAMBDA_MAGNITUDE = 0.1\n",
    "LAMBDA_POLARITY = 0.1\n",
    "LAMBDA_INTEGERS = 0.001\n",
    "LAMBDA_SPARSITY = 0.01\n",
    "X_train, y_train, X_test, y_test = create_torch_XOR_XNOR_dataset()\n",
    "\n",
    "EVALUTION_RUNS = 5\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "# Counter for 100% accuracy runs\n",
    "perfect_accuracy_count = 0\n",
    "evaluation_results = []\n",
    "\n",
    "for _ in range(EVALUTION_RUNS):\n",
    "    model_3_layer_MLP_XNOR_XOR = SparseThreeLayerMLP().double()\n",
    "\n",
    "    # define the loss\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_3_layer_MLP_XNOR_XOR.parameters(), lr=INIITIAL_LEARNING_RATE, eps=1e-7)\n",
    "\n",
    "    all_loss = train_with_rectified_L2(model_3_layer_MLP_XNOR_XOR, \n",
    "                                    loss_function, \n",
    "                                    optimizer, \n",
    "                                    X_train, \n",
    "                                    y_train,\n",
    "                                    no_of_epochs=EPOCHS,\n",
    "                                    ALPHA=ALPHA,\n",
    "                                    LAMBDA_MAGNITUDE=LAMBDA_MAGNITUDE,\n",
    "                                    LAMBDA_POLARITY=LAMBDA_POLARITY,\n",
    "                                    LAMBDA_INTEGERS=LAMBDA_INTEGERS,\n",
    "                                    initial_lr=INIITIAL_LEARNING_RATE,\n",
    "                                    max_lr=MAXIMUM_LEARNING_RATE)\n",
    "\n",
    "    # Evaluate accuracy for the function (A xor B) and (C xnor D)\n",
    "    inputs = [\n",
    "        torch.tensor([[0.0, 0.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 0.0, 0.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 0.0, 1.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 0.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 0.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 1.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[0.0, 1.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 0.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 1.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 0.0, 1.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 0.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 0.0, 1.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 1.0, 0.0]], dtype=torch.float64),\n",
    "        torch.tensor([[1.0, 1.0, 1.0, 1.0]], dtype=torch.float64)\n",
    "    ]\n",
    "    expected_outputs = [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for input_tensor, expected_output in zip(inputs, expected_outputs):\n",
    "        model_output = model_3_layer_MLP_XNOR_XOR(input_tensor).item()\n",
    "        if abs(model_output - expected_output) <= THRESHOLD:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(expected_outputs)\n",
    "\n",
    "    if accuracy > 0.95:\n",
    "        perfect_accuracy_count += 1\n",
    "\n",
    "    # Evaluate interpretability\n",
    "    results = evaluate_logic_gates_in_network(model_3_layer_MLP_XNOR_XOR, 2)\n",
    "    results['accuracy'] = accuracy\n",
    "\n",
    "    evaluation_results.append(results)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('evaluation_results.json', 'w') as f:\n",
    "    json.dump(evaluation_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.2875\n",
      "Average Percentage: 52.857142857142854\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "def load_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Calculate the average accuracy and percentage\n",
    "def calculate_averages(data):\n",
    "    total_accuracy = 0\n",
    "    total_percentage = 0\n",
    "    count = len(data)\n",
    "    \n",
    "    for record in data:\n",
    "        total_accuracy += record[\"accuracy\"]\n",
    "        total_percentage += record[\"percentage\"]\n",
    "    \n",
    "    average_accuracy = total_accuracy / count if count != 0 else 0\n",
    "    average_percentage = total_percentage / count if count != 0 else 0\n",
    "    \n",
    "    return average_accuracy, average_percentage\n",
    "\n",
    "\n",
    "filename = 'evaluation_results.json'  # Replace with your actual JSON file name\n",
    "data = load_json(filename)\n",
    "average_accuracy, average_percentage = calculate_averages(data)\n",
    "\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Average Percentage: {average_percentage}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
