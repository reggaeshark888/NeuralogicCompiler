{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](../images/xor_and_or_nand.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Minimum Integer Set Algorithm\n",
    "- construct linear program that solves the constraints from individual gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 0), (0, 1, 1), (0, 1, 2), (0, 2, 0), (0, 2, 1), (0, 2, 2), (1, 0, 0), (1, 0, 1), (1, 0, 2), (1, 1, 0), (1, 1, 1), (1, 1, 2), (1, 2, 0), (1, 2, 1), (1, 2, 2), (2, 0, 0), (2, 0, 1), (2, 0, 2), (2, 1, 0), (2, 1, 1), (2, 1, 2), (2, 2, 0), (2, 2, 1), (2, 2, 2)]\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10875H CPU @ 2.30GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 218 rows, 57 columns and 618 nonzeros\n",
      "Model fingerprint: 0xe355df86\n",
      "Variable types: 0 continuous, 57 integer (54 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+02]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+00, 2e+01]\n",
      "  RHS range        [1e+00, 1e+02]\n",
      "Presolve removed 132 rows and 30 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 86 rows, 27 columns, 264 nonzeros\n",
      "Variable types: 0 continuous, 27 integer (24 binary)\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "The integer 0 is 10.0\n",
      "The integer 1 is -15.0\n",
      "The integer 2 is 10.0\n",
      "The permutation for NAND is (1, 1, 0)\n",
      "The permutation for AND is (2, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# find the size of the minimum set of integer numbers for representing AND, OR, NAND with a neuron and sigmoid activation function\n",
    "import gurobipy as g\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "NUMBER_OF_INTEGERS = 3\n",
    "NUMBER_OF_HELPER_VARIABLES = pow(NUMBER_OF_INTEGERS, NUMBER_OF_INTEGERS)\n",
    "# Big-M\n",
    "M = 100\n",
    "\n",
    "model = g.Model()\n",
    "\n",
    "# define number of variables\n",
    "int_set = model.addVars(NUMBER_OF_INTEGERS, vtype=g.GRB.INTEGER, lb=-15, ub=15, name=\"x\")\n",
    "\n",
    "\n",
    "# generate all possible permutations with repetition of integer variables\n",
    "numbers = list(range(NUMBER_OF_INTEGERS))\n",
    "all_permutations = list(itertools.product(numbers, repeat=NUMBER_OF_INTEGERS))\n",
    "print(all_permutations)\n",
    "\n",
    "helper_AND_variables = model.addVars(NUMBER_OF_HELPER_VARIABLES, vtype=g.GRB.BINARY, name=\"b1\")\n",
    "# helper_OR_variables = model.addVars(NUMBER_OF_HELPER_VARIABLES, vtype=g.GRB.BINARY, name=\"b2\")\n",
    "# helper_NAND_variables = model.addVars(NUMBER_OF_HELPER_VARIABLES, vtype=g.GRB.BINARY, name=\"b3\")\n",
    "helper_NOR_variables = model.addVars(NUMBER_OF_HELPER_VARIABLES, vtype=g.GRB.BINARY, name=\"b4\")\n",
    "\n",
    "# AND constraints\n",
    "for index, permutation in enumerate(all_permutations):\n",
    "    model.addConstr(0*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_AND_variables[index]) ,f\"AND 1.{permutation}\")\n",
    "    model.addConstr(0*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_AND_variables[index]) ,f\"AND 2.{permutation}\")\n",
    "    model.addConstr(1*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_AND_variables[index]) ,f\"AND 3.{permutation}\")\n",
    "    model.addConstr(1*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_AND_variables[index]) ,f\"AND 4.{permutation}\")\n",
    "\n",
    "\n",
    "model.addConstr(g.quicksum(helper_AND_variables[i] for i in range(NUMBER_OF_HELPER_VARIABLES)) >= 1, \"AtLeastOneANDGroup\")\n",
    "\n",
    "# # OR constraints\n",
    "# for index, permutation in enumerate(all_permutations):\n",
    "#     model.addConstr(0*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_OR_variables[index]) ,f\"OR 1.{permutation}\")\n",
    "#     model.addConstr(0*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_OR_variables[index]) ,f\"OR 2.{permutation}\")\n",
    "#     model.addConstr(1*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_OR_variables[index]) ,f\"OR 3.{permutation}\")\n",
    "#     model.addConstr(1*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_OR_variables[index]) ,f\"OR 4.{permutation}\")\n",
    "\n",
    "\n",
    "# model.addConstr(g.quicksum(helper_OR_variables[i] for i in range(NUMBER_OF_HELPER_VARIABLES)) >= 1, \"AtLeastOneORGroup\")\n",
    "\n",
    "# # NAND constraints\n",
    "# for index, permutation in enumerate(all_permutations):\n",
    "#     model.addConstr(0*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_NAND_variables[index]) ,f\"NAND 1.{permutation}\")\n",
    "#     model.addConstr(0*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_NAND_variables[index]) ,f\"NAND 2.{permutation}\")\n",
    "#     model.addConstr(1*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_NAND_variables[index]) ,f\"NAND 3.{permutation}\")\n",
    "#     model.addConstr(1*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_NAND_variables[index]) ,f\"NAND 4.{permutation}\")\n",
    "\n",
    "# model.addConstr(g.quicksum(helper_NAND_variables[i] for i in range(NUMBER_OF_HELPER_VARIABLES)) >= 1, \"AtLeastOneNANDGroup\")\n",
    "\n",
    "for index, permutation in enumerate(all_permutations):\n",
    "    model.addConstr(0*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] >= 5 - M * (1 - helper_NOR_variables[index]) ,f\"NOR 1.{permutation}\")\n",
    "    model.addConstr(0*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_NOR_variables[index]) ,f\"NOR 2.{permutation}\")\n",
    "    model.addConstr(1*int_set[permutation[0]] + 0*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_NOR_variables[index]) ,f\"NOR 3.{permutation}\")\n",
    "    model.addConstr(1*int_set[permutation[0]] + 1*int_set[permutation[1]] + int_set[permutation[2]] <= -5 + M * (1 - helper_NOR_variables[index]) ,f\"NOR 4.{permutation}\")\n",
    "\n",
    "model.addConstr(g.quicksum(helper_NOR_variables[i] for i in range(NUMBER_OF_HELPER_VARIABLES)) >= 1, \"AtLeastOneNANDGroup\")\n",
    "\n",
    "# Optimize\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "'''\n",
    "The viable integers for representing the set of logic gates\n",
    "'''\n",
    "for index in range(NUMBER_OF_INTEGERS):\n",
    "    print(f\"The integer {index} is {int_set[index].x}\")\n",
    "\n",
    "'''\n",
    "the index of where helper variable is 1 denotes represents the specific permutation, \n",
    "which is viable for representing representing the logic gate\n",
    "'''\n",
    "for index in range(NUMBER_OF_HELPER_VARIABLES):\n",
    "    if (helper_AND_variables[index].x > 0.1):\n",
    "        print(f\"The permutation for AND is {all_permutations[index]}\")\n",
    "    # if (helper_OR_variables[index].x > 0.1):\n",
    "    #     print(f\"The permutation for OR is {all_permutations[index]}\")\n",
    "    # if (helper_NAND_variables[index].x > 0.1):\n",
    "    #     print(f\"The permutation for NAND is {all_permutations[index]}\")\n",
    "    if (helper_NOR_variables[index].x > 0.1):\n",
    "        print(f\"The permutation for NAND is {all_permutations[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "(0, 0, 0)\n",
      "(0, 0, 1)\n",
      "(0, 0, 2)\n",
      "(0, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 1, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 1)\n",
      "(0, 2, 2)\n",
      "(1, 0, 0)\n",
      "(1, 0, 1)\n",
      "(1, 0, 2)\n",
      "(1, 1, 0)\n",
      "(1, 1, 1)\n",
      "(1, 1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 1)\n",
      "(1, 2, 2)\n",
      "(2, 0, 0)\n",
      "(2, 0, 1)\n",
      "(2, 0, 2)\n",
      "(2, 1, 0)\n",
      "(2, 1, 1)\n",
      "(2, 1, 2)\n",
      "(2, 2, 0)\n",
      "(2, 2, 1)\n",
      "(2, 2, 2)\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# maximize distances\n",
    "from itertools import product\n",
    "\n",
    "# Define the elements to permute\n",
    "elements = [0, 1, 2]\n",
    "\n",
    "# Define the length of each permutation\n",
    "permutation_length = 3\n",
    "\n",
    "NUMBER_OF_INTEGERS = 3\n",
    "NUMBER_OF_HELPER_VARIABLES = pow(NUMBER_OF_INTEGERS, NUMBER_OF_INTEGERS)\n",
    "print(NUMBER_OF_HELPER_VARIABLES)\n",
    "# Generate permutations with repeating elements\n",
    "permutations = list(product(elements, repeat=permutation_length))\n",
    "\n",
    "i = 0\n",
    "# Print the permutations\n",
    "for perm in permutations:\n",
    "    print(perm)\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### min weight set for AND and NOR\n",
    "| GATE | BIAS | WEIGHT1 | WEIGHT2 |\n",
    "| AND  |   -6  |    4    |    4    |\n",
    "| NOR  |   4  |    -6    |    -6    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Possible activation functions\n",
    "- sigmoid\n",
    "- threshold function\n",
    "- hyperbolic tanget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# global imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def stable_sigmoid(x):\n",
    "\n",
    "    if x >= 0:\n",
    "        z = math.exp(-x)\n",
    "        sig = 1 / (1 + z)\n",
    "        return sig\n",
    "    else:\n",
    "        z = math.exp(x)\n",
    "        sig = z / (1 + z)\n",
    "        return sig\n",
    "\n",
    "stable_sigmoid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## training ternary neural networks by rectified L2 regularization\n",
    "use it for.:\n",
    "### min weight set for AND and NOR\n",
    "| GATE | BIAS | WEIGHT1 | WEIGHT2 |\n",
    "| AND  |   -6  |    4    |    4    |\n",
    "| NOR  |   4  |    -6    |    -6    |\n",
    "\n",
    "### simplest architecture\n",
    "![](../images/simplest_xor_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden weights: [-4.91343871 -1.47922463] [4.00612084 1.58242818]\n",
      "Final hidden bias: [-2.84768601  1.454252  ]\n",
      "Final output weights: [4.03872877] [-6.06001498]\n",
      "Final output bias: [3.95049173]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.323194] [0.77569961] [0.72262805] [0.27666736]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid (x):\n",
    "\treturn 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "\treturn x * (1 - x)\n",
    "\n",
    "# inputs\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# hyperparameters\n",
    "epochs = 10000\n",
    "lr = 0.1\n",
    "penalty_coefficient = 0.03\n",
    "dual_parameters = [4, -6]\n",
    "threshold = -1\n",
    "\n",
    "# initialize weigths and biases\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "hidden_weights = np.random.uniform(low=-6, high=4, size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(low=-6, high=4, size=(1,hiddenLayerNeurons))\n",
    "output_weights = np.random.uniform(low=-6, high=4, size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(low=-6, high=4, size=(1,outputLayerNeurons))\n",
    "\n",
    "#Training algorithm\n",
    "for _ in range(epochs):\n",
    "\t#Forward Propagation\n",
    "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "\thidden_layer_activation += hidden_bias\n",
    "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "\toutput_layer_activation += output_bias\n",
    "\tpredicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "\t#Backpropagation\n",
    "\terror = expected_output - predicted_output\n",
    "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "\t#Updating Weights and Biases\n",
    "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n",
    "\tx = 0\n",
    "\t# todo: do this properly by backpropagation with matrix operations\n",
    "\tif(epochs > 20):\n",
    "\t\tfor i, weight in enumerate(output_weights):\n",
    "\t\t\tif weight > -1:\n",
    "\t\t\t\toutput_weights[i] = weight - 2*penalty_coefficient*(weight-4)\n",
    "\t\t\telse:\n",
    "\t\t\t\toutput_weights[i] = weight - 2*penalty_coefficient*(weight+6)\n",
    "\n",
    "\t\tif output_bias[0] > -1:\n",
    "\t\t\toutput_bias[0] = output_bias[0] - 2*penalty_coefficient*(output_bias[0]-4)\n",
    "\t\telse:\n",
    "\t\t\toutput_bias[0] = output_bias[0] - 2*penalty_coefficient*(output_bias[0]+6)\n",
    "\n",
    "\t\tfor i, weights in enumerate(hidden_weights):\n",
    "\t\t\tfor j, weight in enumerate(weights):\n",
    "\t\t\t\tif weight > -1:\n",
    "\t\t\t\t\thidden_weights[i,j] = weight - 2*penalty_coefficient*(weight-4)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\thidden_weights[i,j] = weight - 2*penalty_coefficient*(weight+6)\n",
    "\n",
    "\t\tfor i, weights in enumerate(hidden_bias):\n",
    "\t\t\tfor j, weight in enumerate(weights):\n",
    "\t\t\t\tif weight > -1:\n",
    "\t\t\t\t\thidden_bias[i,j] = weight - 2*penalty_coefficient*(weight-4)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\thidden_bias[i,j] = weight - 2*penalty_coefficient*(weight+6)\n",
    "\n",
    "\n",
    "\n",
    "# results\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
