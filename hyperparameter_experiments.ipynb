{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from ternary_weight_mlp import *\n",
    "import torch\n",
    "import json\n",
    "\n",
    "ALPHA = 0.5\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "penalties_magnitude = [0.1, 0.01, 0.001]\n",
    "penalties_polarity = [0.1, 0.01, 0.001]\n",
    "penalties_integers = [0.1, 0.01, 0.001]\n",
    "\n",
    "# Create a grid of all hyperparameter combinations\n",
    "grid = list(itertools.product(learning_rates, penalties_magnitude, penalties_polarity, penalties_integers))\n",
    "\n",
    "# Results list to collect all results\n",
    "results = []\n",
    "\n",
    "for lr, penalty_magnitude, penalty_polarity, penalty_integers in grid:\n",
    "    # dataset\n",
    "    X_train, y_train, X_test, y_test = create_torch_XOR_dataset()\n",
    "\n",
    "    model_XOR = TwoLayerMLP()\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_XOR.parameters(), lr=lr)\n",
    "    \n",
    "    EPOCHS = 10000\n",
    "    \n",
    "    # Assuming you have functions to apply penalties in the model or loss function\n",
    "    train_loss = -1\n",
    "    train_loss_reg = -1\n",
    "\n",
    "    try:\n",
    "        train_loss, train_loss_reg = train_with_rectified_L2(model_XOR, \n",
    "                                    loss_function, \n",
    "                                    optimizer, \n",
    "                                    X_train, \n",
    "                                    y_train,\n",
    "                                    no_of_epochs=EPOCHS,\n",
    "                                    ALPHA=ALPHA,\n",
    "                                    LAMBDA_MAGNITUDE=penalty_magnitude,\n",
    "                                    LAMBDA_POLARITY=penalty_polarity,\n",
    "                                    LAMBDA_INTEGERS=penalty_integers,\n",
    "                                    initial_lr=lr,\n",
    "                                    max_lr=lr)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        params = f\"Training failed for parameters: lr:{lr}, penalty_magnitude:{penalty_magnitude}, penalty_polarity:{penalty_polarity}, penalty_integers:{penalty_integers}\"\n",
    "        print(params)\n",
    "        continue  # Skip this iteration if an error occurs\n",
    "\n",
    "    input1 = torch.tensor([[0.0, 0.0]])\n",
    "    input2 = torch.tensor([[0.0, 1.0]])\n",
    "    input3 = torch.tensor([[1.0, 0.0]])\n",
    "    input4 = torch.tensor([[1.0, 1.0]])\n",
    "\n",
    "    model_XOR.eval()  # Set the model to evaluation mode\n",
    "    output1 = model_XOR(input1).item()\n",
    "    output2 = model_XOR(input2).item()\n",
    "    output3 = model_XOR(input3).item()\n",
    "    output4 = model_XOR(input4).item()\n",
    "\n",
    "    accuracy_counter = 0\n",
    "    if output1 < 0.05:\n",
    "        accuracy_counter += 1\n",
    "    if output2 > 0.95:\n",
    "        accuracy_counter += 1\n",
    "    if output3 > 0.95:\n",
    "        accuracy_counter += 1\n",
    "    if output4 < 0.05:\n",
    "        accuracy_counter += 1\n",
    "    \n",
    "    val_accuracy = accuracy_counter / 4\n",
    "\n",
    "    # Append the results\n",
    "    results.append({\"lr\": lr, \"penalty_magnitude\": penalty_magnitude, \"penalty_polarity\": penalty_polarity,\n",
    "                    \"penalty_integers\": penalty_integers, \"train_loss\": train_loss, \"train_loss_reg\": train_loss_reg,\n",
    "                    \"val_accuracy\": val_accuracy})\n",
    "\n",
    "# Write the collected results to a JSON file\n",
    "results_file = 'hyperparameter_search_results.json'\n",
    "with open(results_file, 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file containing the results\n",
    "results_file = 'hyperparameter_search_results.json'\n",
    "\n",
    "# Load the results from the JSON file\n",
    "with open(results_file, 'r') as file:\n",
    "    results = json.load(file)\n",
    "\n",
    "# Filter results to find only those with 100% validation accuracy\n",
    "optimal_results = [result for result in results if result['val_accuracy'] == 1.0]\n",
    "\n",
    "# Check if there are any optimal results and print them\n",
    "if optimal_results:\n",
    "    print(\"Results with 100% validation accuracy:\")\n",
    "    for result in optimal_results:\n",
    "        print(f\"Learning Rate: {result['lr']}, \"\n",
    "              f\"Penalty Magnitude: {result['penalty_magnitude']}, \"\n",
    "              f\"Penalty Polarity: {result['penalty_polarity']}, \"\n",
    "              f\"Penalty Integers: {result['penalty_integers']}, \"\n",
    "              f\"Train Loss: {result['train_loss'][-1]}, \"\n",
    "              f\"Regularized Train Loss: {result['train_loss_reg'][-1]}, \"\n",
    "              f\"Validation Accuracy: {result['val_accuracy']}\")\n",
    "else:\n",
    "    print(\"No results with 100% validation accuracy.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
